{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "#\tFunctions needed to perform different tasks inside the update routine\n",
    "# -----------------------------------------------------------------\n",
    "import networkx as nx                                            \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def remove_zero_entries_v(A):\n",
    "    \"INPUT:  Multilayer graph A\"\n",
    "    \"OUTPUT: list with INT INDECES of nodes having zero total in_degree over the all layers \"\n",
    "    L=len(A)  # number of layers\n",
    "    zero_in=[]\n",
    "    nodes=list(A[0].nodes())\n",
    "    for i in nodes :  # cycle over nodes\n",
    "        k=0 \n",
    "        for l in range(L):\n",
    "            if(type(A[l].in_degree(i))!=dict):k+=A[l].in_degree(i)\n",
    "        if(k>0):zero_in.append(nodes.index(i))\n",
    "    return zero_in\n",
    "\n",
    "def remove_zero_entries_u(A):\n",
    "    \"INPUT:  Multilayer graph A\"\n",
    "    \"OUTPUT: list with INT INDECES of nodes having zero total out_degree over the all layers \"\n",
    "    L=len(A)  # number of layers\n",
    "    zero_out=[]\n",
    "    nodes=list(A[0].nodes())\n",
    "    for i in nodes:  # cycle over nodes\n",
    "        k=0 \n",
    "        for l in range(L):\n",
    "            if(type(A[l].out_degree(i))!=dict):k+=A[l].out_degree(i)\n",
    "        if(k>0):zero_out.append(nodes.index(i))\t\n",
    "    return zero_out\n",
    "\n",
    "def remove_zero_entries_undirected(A):\n",
    "    \"INPUT:  Multilayer UNDIRECTED graph A\"\n",
    "    \"OUTPUT: list with INT INDECES of nodes having zero total degree over the all layers \"\n",
    "    L=len(A)  # number of layers\n",
    "    zero_in=[]\n",
    "    nodes=list(A[0].nodes())\n",
    "    for i in nodes:  # cycle over nodes\n",
    "        k=0 \n",
    "        for l in range(L):\n",
    "            if(type(A[l].degree(i))!=dict):k+=A[l].degree(i)\n",
    "        if(k>0):zero_in.append(nodes.index(i))\n",
    "    return zero_in\n",
    "\n",
    "def idx(i,A):\n",
    "    \" Adds node i to all layers\"\n",
    "    \" returns node index \"\n",
    "    L=len(A)\n",
    "    if(i not in list(A[0].nodes())):\n",
    "        for l in range(L):A[l].add_node(i)\n",
    "\n",
    "    #return A[0].nodes().index(i)\n",
    "\n",
    "def read_graph(folder,adjacency_file,A):\n",
    "    assert( os.path.isfile(folder+adjacency_file) and os.access(folder+adjacency_file, os.R_OK))\n",
    "    print(\"Adjacency file =\",folder+adjacency_file)\n",
    "    infile=open(folder+adjacency_file,'r');\n",
    "    nr=0\n",
    "    L=len(A)\n",
    "    for line in infile:\n",
    "        a=line.strip('\\n').split()\n",
    "        if(a[0]==\"E\"):  # Flag to check the entry is an edge\n",
    "            if(nr==0): # check format file is ok\n",
    "                l=len(a)-3\n",
    "                assert(l==L)\n",
    "            v1=a[1]\n",
    "            v2=a[2]\n",
    "            idx(v1,A)\n",
    "            idx(v2,A)\n",
    "            for l in range(L):\n",
    "                is_edge=int(a[l+3])\n",
    "                if(is_edge>0):A[l].add_edge(v1, v2, weight=is_edge)\n",
    "    infile.close()\n",
    "\n",
    "def print_graph_stat(A, undirected=False):\n",
    "    L=len(A);N=A[0].number_of_nodes()\n",
    "    print(\"N=\",N)\n",
    "    for l in range(L):\n",
    "        B=nx.to_numpy_matrix(A[l],weight='weight')\n",
    "        if undirected==False: E=np.sum(B)\n",
    "        else:E=0.5*np.sum(B)\n",
    "        print('E[',l,']=',E,\" density=\",100*float(E)/float(N*(N-1)))\n",
    "\n",
    "def out_graph(folder,A):\n",
    "    L=len(A)\n",
    "    for a in range(L):\n",
    "        outfile=folder+\"out_adjacency_\"+str(a)+\".dat\";\n",
    "        outf=open(outfile,'w')\n",
    "        print(\"Adjacency of layer \",a,\" output in: \",outfile)\n",
    "        for e in A[a].edges():\n",
    "            i=e[0]\n",
    "            j=e[1]\n",
    "            print >> outf,i,j\n",
    "        outf.close()\n",
    "        \n",
    "def can_cast(string):\n",
    "    try:\n",
    "        int(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Poisson Tensor factorization for Multi-layer networks.\n",
    "\"\"\"\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "import tools as tl\n",
    "\n",
    "class MultiTensor :\n",
    "    def __init__(self,N=100,L=1,K=2, N_real=1,tolerance=0.1,decision=10,maxit=500,rseed=0,out_adjacency=False,inf=1e10,err_max=0.00001,err=0.1,initialization=0,undirected=False,folder=\"data/\",end_file=\"\",adj=\"adjacency.dat\",w_file=\"w.dat\",assortative=False):\t\n",
    "        self.N=N\n",
    "        self.L=L\n",
    "        self.K=K\n",
    "        self.N_real=N_real\n",
    "        self.tolerance=tolerance\n",
    "        self.decision=decision\n",
    "        self.maxit=maxit\n",
    "        self.rseed=rseed\n",
    "        self.out_adjacency=out_adjacency\n",
    "        self.inf=inf\n",
    "        self.err_max=err_max\n",
    "        self.err=err\n",
    "        self.initialization=initialization\n",
    "        self.undirected=undirected\n",
    "        self.folder=folder\n",
    "        self.end_file=end_file\n",
    "        self.adj=adj\n",
    "        self.w_file=w_file\n",
    "        self.assortative=assortative\n",
    "\n",
    "        # Values used inside the update\n",
    "        self.u=np.zeros((self.N,self.K),dtype=float)  # Out-going membership\n",
    "        self.v=np.zeros((self.N,self.K),dtype=float)  # In-going membership\n",
    "\n",
    "        # Old values\n",
    "        self.u_old=np.zeros((self.N,self.K),dtype=float)  # Out-going membership\n",
    "        self.v_old=np.zeros((self.N,self.K),dtype=float)  # In-going membership\n",
    "        # Final values after convergence --> the ones that maximize Likelihood\n",
    "        self.u_f=np.zeros((self.N,self.K),dtype=float)  # Out-going membership\n",
    "        self.v_f=np.zeros((self.N,self.K),dtype=float)  # In-going membership\n",
    "\n",
    "        if(self.assortative==True): # Purely diagonal matrix\n",
    "            self.w=np.zeros((self.K,self.L),dtype=float)  # Affinity Matrix\n",
    "            self.w_old=np.zeros((self.K,self.L),dtype=float)  # Affinity Matrix\n",
    "            self.w_f=np.zeros((self.K,self.L),dtype=float)  # Affinity Matrix\n",
    "        else:\n",
    "            self.w=np.zeros((self.K,self.K,self.L),dtype=float)  # Affinity Matrix\n",
    "            self.w_old=np.zeros((self.K,self.K,self.L),dtype=float)  # Affinity Matrix\n",
    "            self.w_f=np.zeros((self.K,self.K,self.L),dtype=float)  # Affinity Matrix\n",
    "\n",
    "\n",
    "    def _randomize_w(self,rng):\n",
    "        \" Assign a random number in (0,1.) to each entry\"\n",
    "        for i in range(self.L):\n",
    "            for k in range(self.K):\n",
    "                if(self.assortative==True):self.w[k,i]=rng.random_sample(1)\n",
    "                else:\n",
    "                    for q in range(k,self.K):\n",
    "                        if(q==k):self.w[k,q,i]=rng.random_sample(1)\n",
    "                        else: self.w[k,q,i]=self.w[q,k,i]=self.err*rng.random_sample(1)\n",
    "\n",
    "\n",
    "    def _randomize_u_v(self,rng,u_list,v_list):\n",
    "        \" Randomize the memberships' entries different from zero\"\n",
    "        rng=np.random.RandomState(self.rseed)   # Mersenne-Twister random number generator\n",
    "        for k in range(self.K):\n",
    "            for i in range(len(u_list)):\n",
    "                j=u_list[i]\n",
    "                self.u[j][k]=rng.random_sample(1)\n",
    "                if(self.undirected==True):self.v[j][k]=self.u[j][k]\n",
    "            if(self.undirected==False):\n",
    "                for i in range(len(v_list)):\n",
    "                    j=v_list[i]\n",
    "                    self.v[j][k]=rng.random_sample(1)\n",
    "\n",
    "    def _initialize_w(self,rng,infile_name):\n",
    "        \" Initialize affinity matix from diagonal one extracted from file\"\n",
    "        infile=open(infile_name,'r')\n",
    "        nr=0\n",
    "        for line in infile:\n",
    "            if(nr>0):\n",
    "                a=line.strip('\\n').split()\n",
    "                l=a[0]  # layer index\n",
    "                assert(len(a)==self.K+1)\n",
    "                for k in range(self.K):\n",
    "                    if(assortative==False):self.w[k][k][l]=float(a[k+1])\n",
    "                    else:self.w[k][l]=float(a[k+1])\n",
    "        infile.close()\n",
    "        for l in range(self.L):\n",
    "            for k in range(self.K):\n",
    "                if(self.assortative==True):self.w[k][l]+=self.err*rng.random_sample(1)\n",
    "                else:\n",
    "                    for q in range(self.K):\n",
    "                        self.w[k][q][l]+=self.err*rng.random_sample(1)\n",
    "\n",
    "\n",
    "\n",
    "    def _initialize_u(self,rng,infile_name,nodes):\n",
    "        \" Initialize membership from file and nodes' list\"\n",
    "        \" INPUT 'nodes' is graph node list G.nodes() containing the labels\"\n",
    "        infile=open(infile_name,'r')\n",
    "        nr=0\n",
    "        max_entry=0.\n",
    "        assert(len(nodes)==self.N)\n",
    "        for line in infile:\n",
    "            a= line.strip('\\n').split() # removes \\n and split words in a list of lenght 1+K\n",
    "            if(nr>0 and len(a)>0):\n",
    "                assert(self.K==len(a)-1)\n",
    "                if(a[0] in nodes):\n",
    "                    i=nodes.index(a[0])\n",
    "                    for k in range(self.K):\n",
    "                        z=float(a[k+1])   # Value of the memebership for node a[0] and group k\n",
    "                        self.u[i][k]=z\n",
    "                        max_entry=max(max_entry,z)\n",
    "            nr+=1  \n",
    "        for n in range(self.N):\n",
    "            for k in range(self.K):\n",
    "                self.u[n][k]+=max_entry*self.err*rng.random_sample(1)    \n",
    "        infile.close()    \n",
    "\n",
    "    def _initialize_v(self,rng,infile_name,nodes):\n",
    "        \" Initialize membership from file and nodes' list\"\n",
    "        \" INPUT 'nodes' is graph node list G.nodes() containing the labels\"\n",
    "        if(self.undirected==True):self.v=self.u\n",
    "        else:\n",
    "            infile=open(infile_name,'r')\n",
    "            nr=0\n",
    "            max_entry=0\n",
    "            assert(len(nodes)==self.N)\n",
    "            for line in infile:\n",
    "                a= line.strip('\\n').split() # removes \\n and split words in a list of lenght 1+K\n",
    "                if(nr>0 and len(a)>0):\n",
    "                    assert(self.K==len(a)-1)\n",
    "                    if(a[0] in nodes):\n",
    "                        i=nodes.index(a[0])\n",
    "                        for k in range(self.K):\n",
    "                            z=float(a[k+1])   # Value of the memebership for node a[0] and group k\n",
    "                            self.v[i][k]=z\n",
    "                            max_entry=max(max_entry,z)\n",
    "                nr+=1  \n",
    "            for n in range(self.N):\n",
    "                for k in range(self.K):\n",
    "                    self.v[n][k]+=max_entry*self.err*rng.random_sample(1)      \n",
    "            infile.close()   \n",
    "\n",
    "\n",
    "    def _initialize(self,u_list,v_list,nodes):\n",
    "        rng=np.random.RandomState(self.rseed)   # Mersenne-Twister random number generator\n",
    "        infile1=self.folder+'u_K'+str(self.K)+self.w_file\n",
    "        infile2=self.folder+'v_K'+str(self.K)+self.w_file\n",
    "        w_infile=self.folder+'w_K'+str(self.K)+self.w_file\n",
    "        \n",
    "        if(self.initialization==0):\n",
    "            print(\" Random initializations\")\n",
    "            self._randomize_w(rng)\n",
    "            self._randomize_u_v(rng,u_list,v_list)\n",
    "\n",
    "        elif(self.initialization==1):\n",
    "            print(\" W, U and V are initialized using: \")\n",
    "            print(infile1)\n",
    "            print(infile2)\n",
    "            print(w_infile)\n",
    "            self._initialize_u(rng,infile1,nodes)\n",
    "            self._initialize_v(rng,infile2,nodes)\n",
    "            self._initialize_w(w_infile)\n",
    "\n",
    "        elif(self.initialization==2):\n",
    "            print(\" W initialized using: \")\n",
    "            print(w_infile)\n",
    "            self._initialize_w(rng,w_infile)\n",
    "            self._randomize_u_v(rng,u_list,v_list)\n",
    "        \n",
    "        elif(initialization==3):\n",
    "            print(\" U and V are initialized using: \")\n",
    "            print(infile1)\n",
    "            print(infile2)\n",
    "            self._randomize_w(rng)\n",
    "            self._initialize_u(rng,infile1,nodes)\n",
    "            self._initialize_v(rng,infile2,nodes)\n",
    "\n",
    "    def output_membership(self,nodes):\n",
    "        \" INPUT 'nodes' is graph node list G.nodes() containing the labels\"\n",
    "        print(\" u : \")\n",
    "        for i in range(self.N):\n",
    "            print(nodes[i]),\n",
    "            for k in range(self.K):\n",
    "                print(self.u[i][k]),\n",
    "            print()\n",
    "        print()\n",
    "        if(self.undirected==False):\n",
    "            print(\" v : \")\n",
    "            for i in range(self.N):\n",
    "                print(nodes[i],)\n",
    "                for k in range(self.K):\n",
    "                    print(self.v[i][k],)\n",
    "                print()\n",
    "            \n",
    "    def _output_affinity_matrix(self):\n",
    "        print(\" W:\")\n",
    "        for l in range(self.L):\n",
    "            if(self.assortative==False):\n",
    "                print(\"a=\",l)\n",
    "                for k in range(self.K):\n",
    "                    for q in range(self.K):\n",
    "                        print(self.w[k][q][l],)\n",
    "                    print()\n",
    "                print()\n",
    "            else:\n",
    "                print(l,)\n",
    "                for k in range(self.K):\n",
    "                    print(self.w[k][l],)\n",
    "                print()\n",
    "        print()\n",
    "\n",
    "    def _update_old_variables(self,u_list,v_list):\n",
    "        for i in range(len(u_list)):\n",
    "            for k in range(self.K):\n",
    "                self.u_old[u_list[i]][k]=self.u[u_list[i]][k]\n",
    "        for i in range(len(v_list)):\n",
    "            for k in range(self.K):self.v_old[v_list[i]][k]=self.v[v_list[i]][k]\n",
    "        for l in range(self.L):\n",
    "            for k in range(self.K):\n",
    "                if(self.assortative==True):self.w_old[k][l]=self.w[k][l]\n",
    "                else:\n",
    "                    for q in range(self.K):\n",
    "                        self.w_old[k][q][l]=self.w[k][q][l]\n",
    "\n",
    "\n",
    "    def _update_optimal_parameters(self):\n",
    "        self.u_f=np.copy(self.u)\n",
    "        self.v_f=np.copy(self.v)\n",
    "        self.w_f=np.copy(self.w)\n",
    "\n",
    "    def output_results(self,maxL,nodes):\n",
    "        \" Output results after convergence \"\n",
    "        # SORT node list if possible\n",
    "        sorting=tl.can_cast(nodes[0])\n",
    "        if(sorting==True):\n",
    "            node_list=np.sort( [int(i) for i in nodes] )\n",
    "            print(\"Sorting the membership vectors...\")\n",
    "        infile1=self.folder+\"u_K\"+str(self.K)+self.end_file\n",
    "        infile3=self.folder+\"w_K\"+str(self.K)+self.end_file\n",
    "        in1=open(infile1,'w')\n",
    "        in3=open(infile3,'w')\n",
    "        print(in1,\"# Max Likelihood= \",maxL,\" N_real=\",self.N_real)\n",
    "        print(in3,\"# Max Likelihood= \",maxL,\" N_real=\",self.N_real)\n",
    "        if(self.undirected==False):\n",
    "            infile2=self.folder+\"v_K\"+str(self.K)+self.end_file\n",
    "            in2=open(infile2,'w')\n",
    "            print(\"# Max Likelihood= \",maxL,\" N_real=\",self.N_real, file=in2)\n",
    "\n",
    "\n",
    "        # Output membership\n",
    "\n",
    "        if(sorting==True):\n",
    "            for u in node_list:\n",
    "                i=nodes.index(str(u))\n",
    "                print(u, file=in1)\n",
    "                if(self.undirected==False):print(u, file=in2)\n",
    "                for k in range(self.K):\n",
    "                    print(self.u_f[i][k],file=in1)\n",
    "                    if(self.undirected==False):print(self.v_f[i][k],file=in2)\n",
    "                print(file=in1)\n",
    "                if(self.undirected==False):print(file=in2)\n",
    "        else:\n",
    "            for i in range(self.N):\n",
    "                print(nodes[i],file=in1)\n",
    "                if(self.undirected==False):print(nodes[i],file=in2)\n",
    "                for k in range(self.K):\n",
    "                    print(self.u_f[i][k],file=in1)\n",
    "                    if(self.undirected==False):print(self.v_f[i][k],file=in2)\n",
    "                print(file=in1)\n",
    "                if(self.undirected==False):print(file=in2)\n",
    "\n",
    "        in1.close()\n",
    "\n",
    "        if(self.undirected==False):in2.close()\n",
    "        \n",
    "        # Output affinity matrix\n",
    "        for l in range(self.L):\n",
    "            if(self.assortative==False):\n",
    "                print(\"a=\",l,file=in3)\n",
    "                for k in range(self.K):\n",
    "                    for q in range(self.K):\n",
    "                        print(self.w_f[k][q][l],file=in3)\n",
    "                    print(file=in3)\n",
    "                print(file=in3)\n",
    "            else:\n",
    "                print(l,file=in3)\n",
    "                for k in range(self.K):\n",
    "                    print(self.w_f[k][l],file=in3)\n",
    "                print(file=in3)\n",
    "        in3.close()\n",
    "        \n",
    "        self._output_affinity_matrix()# output on screen\n",
    "\n",
    "        print(\"Data saved in:\")\n",
    "        print(infile1)\n",
    "        print(infile3)\n",
    "        if(self.undirected==False):print(infile2)\n",
    "\n",
    "\n",
    "# \t----------\t----------\t----------\t----------\t----------\t\n",
    "# \t----------  Functions needed in the update_EM routine ----------\t\n",
    "# \t----------\t----------\t----------\t----------\t----------\t\n",
    "\n",
    "    def _update_U(self,A):\n",
    "\n",
    "        Du=np.einsum('iq->q',self.v_old)\n",
    "        if(self.assortative==False):\n",
    "            w_k=np.einsum('kqa->kq',self.w_old)\n",
    "            Z_uk=np.einsum('q,kq->k',Du,w_k)\n",
    "            rho_ijka=np.einsum('jq,kqa->jka',self.v_old,self.w_old)\n",
    "        else:\n",
    "            w_k=np.einsum('ka->k',self.w_old)\n",
    "            Z_uk=np.einsum('k,k->k',Du,w_k)\n",
    "            rho_ijka=np.einsum('jk,ka->jka',self.v_old,self.w_old)\n",
    "        \n",
    "        rho_ijka=np.einsum('ik,jka->ijka',self.u,rho_ijka)\n",
    "\n",
    "        Z_ija=np.einsum('ijka->ija',rho_ijka)\n",
    "        Z_ijka=np.einsum('k,ija->ijka',Z_uk,Z_ija)\n",
    "\n",
    "        non_zeros=Z_ijka>0.\n",
    "        \n",
    "        rho_ijka[non_zeros]/=Z_ijka[non_zeros]\n",
    "\n",
    "        self.u=np.einsum('aij,ijka->ik',A,rho_ijka)\n",
    "        low_values_indices = self.u < self.err_max  # Where values are low\n",
    "        self.u[low_values_indices] = 0.  # All low values set to 0\n",
    "        dist_u=np.amax(abs(self.u-self.u_old))\n",
    "        self.u_old=self.u\n",
    "        return dist_u\n",
    "\n",
    "    def _update_V(self,A):\n",
    "\n",
    "        Dv=np.einsum('iq->q',self.u_old)\n",
    "        if(self.assortative==False):\n",
    "            w_k=np.einsum('qka->qk',self.w_old)\n",
    "            Z_vk=np.einsum('q,qk->k',Dv,w_k)\n",
    "            rho_jika=np.einsum('jq,qka->jka',self.u_old,self.w_old)\n",
    "\n",
    "        else:\t\n",
    "            w_k=np.einsum('ka->k',self.w_old)\n",
    "            Z_vk=np.einsum('k,k->k',Dv,w_k)\n",
    "            rho_jika=np.einsum('jk,ka->jka',self.u_old,self.w_old)\n",
    "\n",
    "        rho_jika=np.einsum('ik,jka->jika',self.v,rho_jika)\n",
    "        \n",
    "        Z_jia=np.einsum('jika->jia',rho_jika)\n",
    "        Z_jika=np.einsum('k,jia->jika',Z_vk,Z_jia)\n",
    "        non_zeros=Z_jika>0.\n",
    "\n",
    "        rho_jika[non_zeros]/=Z_jika[non_zeros]\n",
    "\n",
    "        self.v=np.einsum('aji,jika->ik',A,rho_jika)\n",
    "\n",
    "        low_values_indices = self.v < self.err_max  # Where values are low\n",
    "        self.v[low_values_indices] = 0.  # All low values set to 0\n",
    "        dist_v=np.amax(abs(self.v-self.v_old))\n",
    "        self.v_old=self.v\n",
    "\n",
    "        return dist_v\n",
    "\n",
    "    def _update_W(self,A):\n",
    "\n",
    "        if(self.assortative==False):\n",
    "            uk=np.einsum('ik->k',self.u)\n",
    "            vk=np.einsum('ik->k',self.v)\n",
    "            Z_kq=np.einsum('k,q->kq',uk,vk)\n",
    "            #Z_kq=np.einsum('ik,jq->kq',self.u,self.v)\n",
    "            Z_ija=np.einsum('jq,kqa->jka',self.v,self.w_old)\n",
    "        else:\n",
    "            uk=np.einsum('ik->k',self.u)\n",
    "            vk=np.einsum('ik->k',self.v)\n",
    "            Z_k=np.einsum('k,k->k',uk,vk)\n",
    "            #Z_k=np.einsum('ik,jk->k',self.u,self.v)\n",
    "            Z_ija=np.einsum('jk,ka->jka',self.v,self.w_old)\n",
    "        \n",
    "        Z_ija=np.einsum('ik,jka->ija',self.u,Z_ija)\n",
    "\n",
    "        B=np.einsum('aij->ija',A)\n",
    "        non_zeros=Z_ija>0.\n",
    "        Z_ija[non_zeros]=B[non_zeros]/Z_ija[non_zeros]\n",
    "\n",
    "        rho_ijkqa=np.einsum('ija,ik->jka',Z_ija,self.u)\n",
    "        \n",
    "        if(self.assortative==False):\n",
    "            rho_ijkqa=np.einsum('jka,jq->kqa',rho_ijkqa,self.v)\n",
    "            rho_ijkqa=np.einsum('kqa,kqa->kqa',rho_ijkqa,self.w_old)\n",
    "            self.w=np.einsum('kqa,kq->kqa',rho_ijkqa,1./Z_kq)\n",
    "        else: \n",
    "            rho_ijkqa=np.einsum('jka,jk->ka',rho_ijkqa,self.v)\n",
    "            rho_ijkqa=np.einsum('ka,ka->ka',rho_ijkqa,self.w_old)\n",
    "            self.w=np.einsum('ka,k->ka',rho_ijkqa,1./Z_k)\n",
    "        \n",
    "        low_values_indices = self.w < self.err_max  # Where values are low\n",
    "        self.w[low_values_indices] = 0.  # All low values set to 0\n",
    "\n",
    "        dist_w=np.amax(abs(self.w-self.w_old))\n",
    "        self.w_old=self.w\n",
    "\n",
    "        return dist_w\n",
    "\n",
    "    \n",
    "    def _update_em(self,B):\n",
    "\n",
    "        d_u=self._update_U(B)\n",
    "        if(self.undirected==True):\n",
    "            self.v=self.u\n",
    "            self.v_old=self.v\n",
    "            d_v=d_u\n",
    "        else:\t\n",
    "            d_v=self._update_V(B)\n",
    "        d_w=self._update_W(B)\n",
    "\n",
    "        return d_u,d_v,d_w\n",
    "\n",
    "\n",
    "# \t--------------------------------------------------\n",
    "# \tFunction needed to iterate\n",
    "# \t--------------------------------------------------\n",
    "\n",
    "    def _Likelihood(self,A):\n",
    "        if(self.assortative==False):\n",
    "            mu_ija=np.einsum('kql,jq->klj',self.w,self.v)\n",
    "        else:\n",
    "            mu_ija=np.einsum('kl,jk->klj',self.w,self.v)\n",
    "        mu_ija=np.einsum('ik,klj->lij',self.u,mu_ija)   \n",
    "        l=-mu_ija.sum()\n",
    "        non_zeros=A>0\n",
    "        logM=np.log(mu_ija[non_zeros])\n",
    "        Alog=A[non_zeros]*logM\n",
    "        l+=Alog.sum()\n",
    "        \n",
    "        if(np.isnan(l)):\n",
    "            print(\"Likelihood is NaN!!!!\")\n",
    "            sys.exit(1)\n",
    "        else:return l\n",
    "\n",
    "\n",
    "    def _check_for_convergence(self,B,it,l2,coincide,convergence):\n",
    "        if(it % 10 ==0):\n",
    "            old_L=l2\n",
    "            l2=self._Likelihood(B)\n",
    "            if(abs(l2-old_L)<self.tolerance): coincide+=1\n",
    "            else: coincide=0\n",
    "        if(coincide>self.decision):convergence=True\n",
    "        it+=1\n",
    "\n",
    "        return it,l2,coincide,convergence\n",
    "    def cycle_over_realizations(self,A,B,u_list,v_list):\n",
    "        maxL=-1000000000\n",
    "        nodes=list(A[0].nodes())\n",
    "\n",
    "        for r in range(self.N_real):\n",
    "                \n",
    "            self._initialize(u_list,v_list,nodes)\n",
    "            \n",
    "            self._update_old_variables(u_list,v_list)\n",
    "\n",
    "            # Convergence local variables\n",
    "            coincide=0\n",
    "            convergence=False\n",
    "            it=0\n",
    "            l2=self.inf\n",
    "            #maxL=self.inf\n",
    "            delta_u=delta_v=delta_w=self.inf\n",
    "\n",
    "            print(\"Updating r=\",r,\" ...\")\n",
    "            tic=time.clock()\n",
    "            # ------------------- Single step iteration update ------------------*/\n",
    "            while(convergence==False and it<self.maxit):\n",
    "                # Main EM update: updates membership and calculates max difference new vs old\n",
    "                delta_u,delta_v,delta_w=self._update_em(B)\n",
    "\n",
    "                it,l2,coincide,convergence=self._check_for_convergence(B,it,l2,coincide,convergence)\n",
    "            print(\"r=\",r,\" Likelihood=\",l2,\" iterations=\",it,' time=',time.clock()-tic,'s')\n",
    "            if(maxL<l2): \n",
    "                self._update_optimal_parameters()\n",
    "                maxL=l2\n",
    "            self.rseed+=1\n",
    "        # end cycle over realizations\n",
    "    \n",
    "        print(\"Final Likelihood=\",maxL)\n",
    "\n",
    "        self.output_results(maxL,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6220efca8c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-6220efca8c85>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDiGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m   \u001b[0;31m# list of graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Undirected=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundirected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Assortative=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massortative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/MultiTensor-master/python/tools.py\u001b[0m in \u001b[0;36mread_graph\u001b[0;34m(folder, adjacency_file, A)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madjacency_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0madjacency_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0madjacency_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR_OK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adjacency file =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0madjacency_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0minfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0madjacency_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import MultiTensor as mt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from argparse import ArgumentParser\n",
    "import sys\n",
    "import tools as tl\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    inf=10000000000000\n",
    "    err_max=0.0000001\n",
    "    p = ArgumentParser()\n",
    "    p.add_argument('-f', '--folder', type=str, default='')\n",
    "    p.add_argument('-a', '--adj', type=str, default='adjacency.dat')\n",
    "    p.add_argument('-E', '--end_file', type=str, default='.dat')\n",
    "    p.add_argument('-w', '--w_file', type=str, default='w.dat')\n",
    "    p.add_argument('-l', '--L', type=int, default=4)\n",
    "    p.add_argument('-i', '--initialization', type=int, default=0)\n",
    "    p.add_argument('-k', '--K', type=int, default=5)\n",
    "    p.add_argument('-r', '--N_real', type=int, default=1)\n",
    "    p.add_argument('-t', '--maxit', type=int, default=500)\n",
    "    p.add_argument('-e', '--tolerance', type=float,default=0.1)\n",
    "    p.add_argument('-g', '--err', type=float,default=0.1)\n",
    "    p.add_argument('-o','--out_adjacency',type=int,default=0)\n",
    "    p.add_argument('-A','--assortative',type=int,default=0)\n",
    "    p.add_argument('-u','--undirected',type=int,default=0)\n",
    "    p.add_argument('-z', '--rseed', type=int, default=0)\n",
    "    p.add_argument('-y','--decision',type=int,default=2)\n",
    "    args = p.parse_args()\n",
    "    \n",
    "    folder=\"../data/\"+args.folder\n",
    "    if(args.undirected==True):A=[ nx.MultiGraph() for l in range(args.L) ]   # list of graphs\n",
    "    else:A=[ nx.MultiDiGraph() for l in range(args.L) ]   # list of graphs\n",
    "\n",
    "    tl.read_graph(folder,args.adj,A)\n",
    "    print(\"Undirected=\",bool(args.undirected))\n",
    "    print(\"Assortative=\",bool(args.assortative))\n",
    "    tl.print_graph_stat(A,args.undirected)\n",
    "\n",
    "    if(args.out_adjacency):tl.out_graph(folder,A)\n",
    "\n",
    "    if(args.undirected==True):\n",
    "        u_list=v_list=tl.remove_zero_entries_undirected(A) \n",
    "    else:\n",
    "        u_list=tl.remove_zero_entries_u(A)   # list of INT INDECES of nodes with zero out degree\n",
    "        v_list=tl.remove_zero_entries_v(A)   # list of INT INDECES of nodes with zero in degree\n",
    "\n",
    "    MT=mt.MultiTensor(  N=A[0].number_of_nodes(),\n",
    "            L=args.L,K=args.K, \n",
    "            N_real=args.N_real,\n",
    "            tolerance=args.tolerance,\n",
    "            decision=args.decision,\n",
    "            maxit=args.maxit,\n",
    "            rseed=args.rseed,\n",
    "            out_adjacency=bool(args.out_adjacency),\n",
    "            inf=inf,\n",
    "            err_max=err_max,\n",
    "            err=args.err,\n",
    "            initialization=args.initialization,\n",
    "            undirected=bool(args.undirected),\n",
    "            folder=folder,\n",
    "            end_file=args.end_file,\n",
    "            adj=args.adj,\n",
    "            w_file=args.w_file,\n",
    "            assortative=bool(args.assortative)\n",
    "            )\n",
    "\n",
    "    tic = time.clock()\n",
    "    N=A[0].number_of_nodes()\n",
    "    B=np.empty(shape=[args.L,N,N])\n",
    "\n",
    "    for l in range(args.L):B[l,:,:]=nx.to_numpy_matrix(A[l],weight='weight')\n",
    "    \n",
    "    MT.cycle_over_realizations(A,B,u_list,v_list)\n",
    "\n",
    "    #tl.print_graph_stat(A)\n",
    "    toc = time.clock()\n",
    "    print(\"It took \",toc-tic,\" seconds.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
